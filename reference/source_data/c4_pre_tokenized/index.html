<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>c4_pre_tokenized - Sparse Autoencoder</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "c4_pre_tokenized";
        var mkdocs_page_input_path = "reference/source_data/c4_pre_tokenized.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> Sparse Autoencoder
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../getting_started/">Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../contributing/">Contributing</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../citation/">Citation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Reference</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../">Home</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">activation_resampler</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_resampler/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_resampler/abstract_activation_resampler/">abstract_activation_resampler</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_resampler/activation_resampler/">activation_resampler</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">activation_store</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/base_store/">base_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/disk_store/">disk_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/list_store/">list_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/tensor_store/">tensor_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">utils</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../activation_store/utils/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../activation_store/utils/extend_resize/">extend_resize</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">autoencoder</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/abstract_autoencoder/">abstract_autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">components</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_decoder/">abstract_decoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_encoder/">abstract_encoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_outer_bias/">abstract_outer_bias</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/linear_encoder/">linear_encoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/tied_bias/">tied_bias</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/unit_norm_decoder/">unit_norm_decoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/unit_norm_linear/">unit_norm_linear</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/fista_autoencoder/">fista_autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/loss/">loss</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/model/">model</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">loss</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/abstract_loss/">abstract_loss</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/fista/">fista</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/learned_activations_l1/">learned_activations_l1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/mse_reconstruction_loss/">mse_reconstruction_loss</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/reducer/">reducer</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">metrics</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../metrics/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../metrics/abstract_metric/">abstract_metric</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">generate</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/generate/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/generate/abstract_generate_metric/">abstract_generate_metric</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">train</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/train/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/train/abstract_train_metric/">abstract_train_metric</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">validate</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/validate/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../metrics/validate/abstract_validate_metric/">abstract_validate_metric</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">optimizer</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/abstract_optimizer/">abstract_optimizer</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/adam_with_reset/">adam_with_reset</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">source_data</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../abstract_dataset/">abstract_dataset</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="./">c4_pre_tokenized</a>
    <ul class="current">
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../pile_uncopyrighted/">pile_uncopyrighted</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../pretokenized_dataset/">pretokenized_dataset</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../random_int/">random_int</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../text_dataset/">text_dataset</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">source_model</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../source_model/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../source_model/store_activations_hook/">store_activations_hook</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">src_model</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../src_model/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../src_model/store_activations_hook/">store_activations_hook</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tensor_types/">tensor_types</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">train</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../train/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/abstract_pipeline/">abstract_pipeline</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/generate_activations/">generate_activations</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">metrics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/capacity/">capacity</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/feature_density/">feature_density</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/pipeline/">pipeline</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/resample_neurons/">resample_neurons</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/sweep_config/">sweep_config</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/train_autoencoder/">train_autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">utils</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../train/utils/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/utils/get_model_device/">get_model_device</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/utils/wandb_sweep_types/">wandb_sweep_types</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">Sparse Autoencoder</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Reference</li>
          <li class="breadcrumb-item">source_data</li>
      <li class="breadcrumb-item active">c4_pre_tokenized</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">



<a id="sparse_autoencoder.source_data.c4_pre_tokenized"></a>
  <div class="doc doc-contents first">
  
      <p>Neel Nanda C4 Pre-Tokenized 2B Dataset.</p>
<p>This dataset was used to train <a href="https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html">Neel Nanda's GeLU
models</a>. These
are known in TransformerLens as <code>gelu-1l</code> to <code>gelu-4l</code>. The dataset is pre-tokenized.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataBatch" class="doc doc-heading">
          <code>NeelC4SourceDataBatch</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="typing.TypedDict">TypedDict</span></code></p>

  
      <p>Neel Nanda C4 Pre-Tokenized 2B Dataset Item.</p>
<p>https://huggingface.co/datasets/NeelNanda/c4-tokenized-2b</p>

            <details class="quote">
              <summary>Source code in <code>sparse_autoencoder/source_data/c4_pre_tokenized.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">NeelC4SourceDataBatch</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Neel Nanda C4 Pre-Tokenized 2B Dataset Item.</span>

<span class="sd">    https://huggingface.co/datasets/NeelNanda/c4-tokenized-2b</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h2 id="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataset" class="doc doc-heading">
          <code>NeelC4SourceDataset</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="sparse_autoencoder.source_data.abstract_dataset.SourceDataset" href="../abstract_dataset/#sparse_autoencoder.source_data.abstract_dataset.SourceDataset">SourceDataset</a>[<a class="autorefs autorefs-internal" title="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataBatch" href="#sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataBatch">NeelC4SourceDataBatch</a>]</code></p>

  
      <p>Neel Nanda C4 Pre-Tokenized 2B Dataset.</p>
<p>https://huggingface.co/datasets/monology/pile-uncopyrighted</p>

            <details class="quote">
              <summary>Source code in <code>sparse_autoencoder/source_data/c4_pre_tokenized.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@final</span>
<span class="k">class</span> <span class="nc">NeelC4SourceDataset</span><span class="p">(</span><span class="n">SourceDataset</span><span class="p">[</span><span class="n">NeelC4SourceDataBatch</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Neel Nanda C4 Pre-Tokenized 2B Dataset.</span>

<span class="sd">    https://huggingface.co/datasets/monology/pile-uncopyrighted</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">source_batch</span><span class="p">:</span> <span class="n">NeelC4SourceDataBatch</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenizedPrompts</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Preprocess a batch of prompts.</span>

<span class="sd">        As this dataset is already tokenized, all this does is split up each item based on the</span>
<span class="sd">        context size.</span>

<span class="sd">        Args:</span>
<span class="sd">            source_batch: A batch of source data.</span>
<span class="sd">            context_size: The context size to use when returning a list of tokenized prompts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokenized_prompts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">source_batch</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>

        <span class="c1"># Chunk each tokenized prompt into blocks of context_size, discarding the last block if too</span>
        <span class="c1"># small.</span>
        <span class="n">context_size_prompts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">tokenized_prompts</span><span class="p">:</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">encoding</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">context_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">),</span> <span class="n">context_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">context_size</span><span class="p">])</span> <span class="o">==</span> <span class="n">context_size</span>
            <span class="p">]</span>
            <span class="n">context_size_prompts</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">context_size_prompts</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
        <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">preprocess_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;NeelNanda/c4-tokenized-2b&quot;</span><span class="p">,</span>
        <span class="n">dataset_split</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Pile Uncopyrighted dataset.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; data = NeelC4SourceDataset()</span>
<span class="sd">            &gt;&gt;&gt; first_item = next(iter(data))</span>
<span class="sd">            &gt;&gt;&gt; len(first_item[&quot;input_ids&quot;])</span>
<span class="sd">            250</span>

<span class="sd">        Args:</span>
<span class="sd">            context_size: The context size to use when returning a list of tokenized prompts.</span>
<span class="sd">                *Towards Monosemanticity: Decomposing Language Models With Dictionary Learning* used</span>
<span class="sd">                a context size of 250.</span>
<span class="sd">            buffer_size: The buffer size to use when shuffling the dataset. As the dataset is</span>
<span class="sd">                streamed, this just pre-downloads at least `buffer_size` items and then shuffles</span>
<span class="sd">                just that buffer. Note that the generated activations should also be shuffled before</span>
<span class="sd">                training the sparse autoencoder, so a large buffer may not be strictly necessary</span>
<span class="sd">                here. Note also that this is the number of items in the dataset (e.g. number of</span>
<span class="sd">                prompts) and is typically significantly less than the number of tokenized prompts</span>
<span class="sd">                once the preprocessing function has been applied.</span>
<span class="sd">            preprocess_batch_size: The batch size to use just for preprocessing the dataset (e.g.</span>
<span class="sd">                tokenizing prompts).</span>
<span class="sd">            dataset_path: The path to the dataset on Hugging Face.</span>
<span class="sd">            dataset_split: Dataset split (e.g. `train`).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">dataset_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="n">dataset_split</span><span class="o">=</span><span class="n">dataset_split</span><span class="p">,</span>
            <span class="n">context_size</span><span class="o">=</span><span class="n">context_size</span><span class="p">,</span>
            <span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">,</span>
            <span class="n">preprocess_batch_size</span><span class="o">=</span><span class="n">preprocess_batch_size</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataset.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">context_size</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">preprocess_batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dataset_path</span><span class="o">=</span><span class="s1">&#39;NeelNanda/c4-tokenized-2b&#39;</span><span class="p">,</span> <span class="n">dataset_split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initialize the Pile Uncopyrighted dataset.</p>

<details class="example" open>
  <summary>Example</summary>
  <blockquote>
<blockquote>
<blockquote>
<p>data = NeelC4SourceDataset()
first_item = next(iter(data))
len(first_item["input_ids"])
250</p>
</blockquote>
</blockquote>
</blockquote>
</details>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>context_size</code></b>
                  (<code>int</code>, default:
                      <code>250</code>
)
              –
              <div class="doc-md-description">
                <p>The context size to use when returning a list of tokenized prompts.
<em>Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</em> used
a context size of 250.</p>
              </div>
            </li>
            <li>
              <b><code>buffer_size</code></b>
                  (<code>int</code>, default:
                      <code>1000</code>
)
              –
              <div class="doc-md-description">
                <p>The buffer size to use when shuffling the dataset. As the dataset is
streamed, this just pre-downloads at least <code>buffer_size</code> items and then shuffles
just that buffer. Note that the generated activations should also be shuffled before
training the sparse autoencoder, so a large buffer may not be strictly necessary
here. Note also that this is the number of items in the dataset (e.g. number of
prompts) and is typically significantly less than the number of tokenized prompts
once the preprocessing function has been applied.</p>
              </div>
            </li>
            <li>
              <b><code>preprocess_batch_size</code></b>
                  (<code>int</code>, default:
                      <code>1000</code>
)
              –
              <div class="doc-md-description">
                <p>The batch size to use just for preprocessing the dataset (e.g.
tokenizing prompts).</p>
              </div>
            </li>
            <li>
              <b><code>dataset_path</code></b>
                  (<code>str</code>, default:
                      <code>&#39;NeelNanda/c4-tokenized-2b&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>The path to the dataset on Hugging Face.</p>
              </div>
            </li>
            <li>
              <b><code>dataset_split</code></b>
                  (<code>str</code>, default:
                      <code>&#39;train&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>Dataset split (e.g. <code>train</code>).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>sparse_autoencoder/source_data/c4_pre_tokenized.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span>
    <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">preprocess_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;NeelNanda/c4-tokenized-2b&quot;</span><span class="p">,</span>
    <span class="n">dataset_split</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the Pile Uncopyrighted dataset.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; data = NeelC4SourceDataset()</span>
<span class="sd">        &gt;&gt;&gt; first_item = next(iter(data))</span>
<span class="sd">        &gt;&gt;&gt; len(first_item[&quot;input_ids&quot;])</span>
<span class="sd">        250</span>

<span class="sd">    Args:</span>
<span class="sd">        context_size: The context size to use when returning a list of tokenized prompts.</span>
<span class="sd">            *Towards Monosemanticity: Decomposing Language Models With Dictionary Learning* used</span>
<span class="sd">            a context size of 250.</span>
<span class="sd">        buffer_size: The buffer size to use when shuffling the dataset. As the dataset is</span>
<span class="sd">            streamed, this just pre-downloads at least `buffer_size` items and then shuffles</span>
<span class="sd">            just that buffer. Note that the generated activations should also be shuffled before</span>
<span class="sd">            training the sparse autoencoder, so a large buffer may not be strictly necessary</span>
<span class="sd">            here. Note also that this is the number of items in the dataset (e.g. number of</span>
<span class="sd">            prompts) and is typically significantly less than the number of tokenized prompts</span>
<span class="sd">            once the preprocessing function has been applied.</span>
<span class="sd">        preprocess_batch_size: The batch size to use just for preprocessing the dataset (e.g.</span>
<span class="sd">            tokenizing prompts).</span>
<span class="sd">        dataset_path: The path to the dataset on Hugging Face.</span>
<span class="sd">        dataset_split: Dataset split (e.g. `train`).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">dataset_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span>
        <span class="n">dataset_split</span><span class="o">=</span><span class="n">dataset_split</span><span class="p">,</span>
        <span class="n">context_size</span><span class="o">=</span><span class="n">context_size</span><span class="p">,</span>
        <span class="n">buffer_size</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">,</span>
        <span class="n">preprocess_batch_size</span><span class="o">=</span><span class="n">preprocess_batch_size</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataset.preprocess" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">preprocess</span><span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">context_size</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Preprocess a batch of prompts.</p>
<p>As this dataset is already tokenized, all this does is split up each item based on the
context size.</p>



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>source_batch</code></b>
                  (<code><a class="autorefs autorefs-internal" title="sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataBatch" href="#sparse_autoencoder.source_data.c4_pre_tokenized.NeelC4SourceDataBatch">NeelC4SourceDataBatch</a></code>)
              –
              <div class="doc-md-description">
                <p>A batch of source data.</p>
              </div>
            </li>
            <li>
              <b><code>context_size</code></b>
                  (<code>int</code>)
              –
              <div class="doc-md-description">
                <p>The context size to use when returning a list of tokenized prompts.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>sparse_autoencoder/source_data/c4_pre_tokenized.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">source_batch</span><span class="p">:</span> <span class="n">NeelC4SourceDataBatch</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">context_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TokenizedPrompts</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Preprocess a batch of prompts.</span>

<span class="sd">    As this dataset is already tokenized, all this does is split up each item based on the</span>
<span class="sd">    context size.</span>

<span class="sd">    Args:</span>
<span class="sd">        source_batch: A batch of source data.</span>
<span class="sd">        context_size: The context size to use when returning a list of tokenized prompts.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokenized_prompts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">source_batch</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span>

    <span class="c1"># Chunk each tokenized prompt into blocks of context_size, discarding the last block if too</span>
    <span class="c1"># small.</span>
    <span class="n">context_size_prompts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">tokenized_prompts</span><span class="p">:</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">encoding</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">context_size</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">),</span> <span class="n">context_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">context_size</span><span class="p">])</span> <span class="o">==</span> <span class="n">context_size</span>
        <span class="p">]</span>
        <span class="n">context_size_prompts</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">context_size_prompts</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../abstract_dataset/" class="btn btn-neutral float-left" title="abstract_dataset"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../pile_uncopyrighted/" class="btn btn-neutral float-right" title="pile_uncopyrighted">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../abstract_dataset/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../pile_uncopyrighted/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
